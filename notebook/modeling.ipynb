{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6e5200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Setup\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dvc.api\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import functions from task4_modeling\n",
    "from src.modeling import (prepare_data, build_models, evaluate_models, interpret_model)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Define data paths\n",
    "cleaned_data_path = '../data/cleaned_data.csv'\n",
    "dvc_file = '../data/cleaned_data.csv.dvc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfafb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preparation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\src\\eda_analysis.py:50: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['ClaimSeverity'] = df['ClaimSeverity'].fillna(0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No valid data left for severity modeling after cleaning.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Data Preparation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting data preparation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_train_sev, X_test_sev, y_train_sev, y_test_sev, X_train_prob, X_test_prob, y_train_prob, y_test_prob = \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdvc_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData preparation completed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\src\\modeling.py:64\u001b[39m, in \u001b[36mprepare_data\u001b[39m\u001b[34m(df_path, dvc_file)\u001b[39m\n\u001b[32m     61\u001b[39m y_sev = df_severity[\u001b[33m'\u001b[39m\u001b[33mTotalClaims\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_sev.empty \u001b[38;5;129;01mor\u001b[39;00m y_sev.empty:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo valid data left for severity modeling after cleaning.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(X_sev, y_sev, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# === Split for Probability Model ===\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: No valid data left for severity modeling after cleaning."
     ]
    }
   ],
   "source": [
    "## Data Preparation\n",
    "print(\"Starting data preparation...\")\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev, X_train_prob, X_test_prob, y_train_prob, y_test_prob = prepare_data(cleaned_data_path, dvc_file)\n",
    "print(\"Data preparation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building models...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Model Building\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBuilding models...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m models_sev, models_prob = \u001b[43mbuild_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel building completed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\src\\modeling.py:85\u001b[39m, in \u001b[36mbuild_models\u001b[39m\u001b[34m(X_train_sev, y_train_sev, X_train_prob, y_train_prob)\u001b[39m\n\u001b[32m     78\u001b[39m models_sev = {\n\u001b[32m     79\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLinear Regression\u001b[39m\u001b[33m'\u001b[39m: LinearRegression(),\n\u001b[32m     80\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDecision Tree\u001b[39m\u001b[33m'\u001b[39m: DecisionTreeRegressor(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m     81\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m: RandomForestRegressor(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m     82\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m: XGBRegressor(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     83\u001b[39m }\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_sev.values():\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m models_prob = {\n\u001b[32m     88\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m: RandomForestClassifier(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m     89\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m: XGBClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     90\u001b[39m }\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_prob.values():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1145\u001b[39m     estimator._validate_params()\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1148\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1149\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1150\u001b[39m     )\n\u001b[32m   1151\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    674\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    676\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    680\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    682\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\base.py:622\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[39m\n\u001b[32m    620\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    623\u001b[39m     out = X, y\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1141\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1143\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1144\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1164\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    952\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    953\u001b[39m             % (array.ndim, estimator_name)\n\u001b[32m    954\u001b[39m         )\n\u001b[32m    956\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples > \u001b[32m0\u001b[39m:\n\u001b[32m    965\u001b[39m     n_samples = _num_samples(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Senayit\\Documents\\1\\week3\\acis_project_week3\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    156\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    157\u001b[39m     msg_err += (\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "## Model Building\n",
    "print(\"Building models...\")\n",
    "models_sev, models_prob = build_models(X_train_sev, y_train_sev, X_train_prob, y_train_prob)\n",
    "print(\"Model building completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925540f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models_sev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Model Evaluation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating models...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results_sev, results_prob = evaluate_models(\u001b[43mmodels_sev\u001b[49m, models_prob, X_test_sev, y_test_sev, X_test_prob, y_test_prob)\n",
      "\u001b[31mNameError\u001b[39m: name 'models_sev' is not defined"
     ]
    }
   ],
   "source": [
    "## Model Evaluation\n",
    "print(\"Evaluating models...\")\n",
    "results_sev, results_prob = evaluate_models(models_sev, models_prob, X_test_sev, y_test_sev, X_test_prob, y_test_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"\\n=== Claim Severity Model Results ===\")\n",
    "for name, result in results_sev.items():\n",
    "    print(f\"{name}: RMSE = {result['RMSE']:.2f}, R² = {result['R²']:.4f}\")\n",
    "\n",
    "print(\"\\n=== Claim Probability Model Results ===\")\n",
    "for name, result in results_prob.items():\n",
    "    print(f\"{name}: Accuracy = {result['Accuracy']:.4f}, Precision = {result['Precision']:.4f}, \"\n",
    "          f\"Recall = {result['Recall']:.4f}, F1 = {result['F1']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5096c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "best_sev_model = max(results_sev, key=lambda k: results_sev[k]['R²'])\n",
    "best_prob_model = max(results_prob, key=lambda k: results_prob[k]['F1'])\n",
    "print(f\"\\n=== Model Comparison ===\")\n",
    "print(f\"Best Claim Severity Model (by R²): {best_sev_model}\")\n",
    "print(f\"Best Claim Probability Model (by F1): {best_prob_model}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3986cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Interpretability\n",
    "print(\"Performing model interpretability...\")\n",
    "# Interpret best severity model\n",
    "best_sev = models_sev[best_sev_model]\n",
    "interpret_model(best_sev, X_train_sev, X_test_sev, 'severity')\n",
    "\n",
    "# Interpret best probability model\n",
    "best_prob = models_prob[best_prob_model]\n",
    "interpret_model(best_prob, X_train_prob, X_test_prob, 'probability')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
